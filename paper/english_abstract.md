Tokenization is the first step in the input of a large language model (hereinafter referred to as a LLM). At present, the tokenizer of state-of-the-sart LLMs including OpenAI[1], Tongyi Qianwen[2] and Deepseek[3] are all constructed from massive text data using the byte-level BPE method. Although these models have excellent performance in various tasks, there is still a question to be answered, i.e., what impact does the tokenization result have on the LLMs? In this paper, based on the observation of the tokenization results and vocabulary of three models, GPT-4o[1], Qwen2.5-72b-Instruct[4] and Deepseek-v3[5], I constructed: 1) four groups of prompts that may be caused by tokenization errors/ambiguous transmission and answer errors; 2) a group of 1-shot ambiguous sentence generation prompt. The results show that word segmentation is still an important issue for large models, which requires more investment in analysis and optimization. Finally, I proposed some potential solutions. Code and data of this paper have been uploaded to the github project: https://github.com/zhaoyukoon/damoxing_fenci_gongji.
